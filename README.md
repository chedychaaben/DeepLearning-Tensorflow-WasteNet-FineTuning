# WasteNet-FineTuning ğŸŒâ™»ï¸

Welcome to **WasteNet-FineTuning**, a deep learning project for waste classification using Convolutional Neural Networks (CNNs) with TensorFlow! ğŸš€ This repository implements a fine-tuned ResNet50-based model to classify waste images, leveraging transfer learning and data augmentation for robust performance. Perfect for researchers and developers interested in sustainable AI solutions! ğŸŒ±

## ğŸ“– Project Overview

This project focuses on building and fine-tuning a CNN model for binary waste classification (e.g., organic vs. recyclable). It uses a pretrained ResNet50 model on ImageNet, enhanced with data augmentation and custom layers, to process 48x48 RGB images. The model is trained and evaluated on a waste dataset, with performance visualized via confusion matrices. ğŸ“Š

Key features:
- ğŸ§  Fine-tuned ResNet50 architecture for waste classification
- ğŸ”„ Data augmentation (rotation, zoom, horizontal flip)
- âš¡ Optimized data loading with caching and prefetching
- âœ… Early stopping and model checkpointing for efficient training
- ğŸ“ˆ Confusion matrix visualization for model evaluation

## ğŸ› ï¸ Setup

Follow these steps to set up the project in a Google Colab environment or locally with Python.

### Prerequisites
- Python 3.8+ ğŸ
- TensorFlow 2.x
- Libraries: `numpy`, `pandas`, `seaborn`, `matplotlib`, `scikit-learn`
- Google Drive for dataset and model weight storage (if using Colab) â˜ï¸
- Dataset: `waste_dataset` (unzipped in `/content/drive/MyDrive/waste_dataset`)

### Installation
1. **Clone the Repository**:
   ```bash
   git clone https://github.com/<your-username>/WasteNet-FineTuning.git
   cd WasteNet-FineTuning
   ```

2. **Install Dependencies**:
   ```bash
   pip install tensorflow numpy pandas seaborn matplotlib scikit-learn
   ```

3. **Google Colab Setup** (if applicable):
   - Mount Google Drive in Colab:
     ```python
     from google.colab import drive
     drive.mount('/content/drive')
     ```
   - Unzip the dataset:
     ```bash
     !unzip /content/drive/MyDrive/waste_dataset.zip -d /content/drive/MyDrive/
     ```

4. **Prepare the Dataset**:
   - Ensure the `waste_dataset` folder contains `Train` and `Test` subdirectories with images.
   - Place `test_dechets.csv` in `/content/drive/MyDrive/` for evaluation.

## ğŸš€ Usage

1. **Run the Notebook**:
   - Open `WasteNet-FineTuning.ipynb` in Jupyter or Google Colab.
   - Execute the cells sequentially to:
     - Load and preprocess the dataset ğŸ“‚
     - Build and compile the CNN model ğŸ§ 
     - Train the model with early stopping and checkpointing âš™ï¸
     - Evaluate performance using a confusion matrix ğŸ“Š

2. **Key Steps in the Notebook**:
   - **Data Loading**: Loads RGB images (48x48) into `train_ds`, `val_ds`, and `test_ds` with a batch size of 64.
   - **Model Building**: Constructs `p_m_dechets2` using ResNet50 and custom layers (see Figure 2 in the notebook).
   - **Training**: Trains for 10 epochs with Adam optimizer, monitoring `val_accuracy`.
   - **Evaluation**: Generates predictions and visualizes the confusion matrix.

3. **Example Command** (for local execution):
   ```bash
   jupyter notebook WasteNet-FineTuning.ipynb
   ```

## ğŸ“‚ Dataset

The `waste_dataset` contains:
- **Train**: Training images, split into 80% training and 20% validation.
- **Test**: Test images for evaluation.
- **test_dechets.csv**: CSV file with test data and labels for confusion matrix generation.

Ensure the dataset is structured as:
```
/content/drive/MyDrive/waste_dataset/
â”œâ”€â”€ Train/
â”‚   â”œâ”€â”€ class1/
â”‚   â”œâ”€â”€ class2/
â”œâ”€â”€ Test/
â”‚   â”œâ”€â”€ class1/
â”‚   â”œâ”€â”€ class2/
```

## ğŸ§ª Multi-Input Model

The notebook also includes a multi-input model combining ResNet50 and VGG16 features for a 3-class classification task. This requires two datasets (`Dataset1` and `Dataset2`) with identical labels. Update the paths in the notebook if using this feature.

## ğŸ“ˆ Results

After training, the model saves the best weights to `/content/drive/MyDrive/p_m_dechets2.weights.h5`. The confusion matrix visualizes performance on the test set, with labels `O` (organic) and `R` (recyclable). Example output:
- **Accuracy**: Computed per epoch for training and validation.
- **Confusion Matrix**: Shows true vs. predicted labels.

## ğŸ¤ Contributing

Contributions are welcome! ğŸ™Œ Feel free to:
- Open issues for bugs or feature requests ğŸ
- Submit pull requests with improvements ğŸ”§
- Share feedback on model performance or dataset quality ğŸ“¬

## ğŸ“œ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- TensorFlow team for the awesome deep learning framework
- ImageNet for pretrained weights
- The waste classification community for inspiring sustainable AI ğŸŒ

Happy coding and classifying! ğŸ‰